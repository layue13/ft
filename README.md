# Gemma3-1b å·¥å…·è°ƒç”¨å¾®è°ƒé¡¹ç›® - ä¼˜åŒ–ç‰ˆæœ¬

ä½¿ç”¨PEFTï¼ˆParameter Efficient Fine-Tuningï¼‰å¾®è°ƒGemma3-1bæ¨¡å‹ï¼Œä½¿å…¶æ”¯æŒå·¥å…·è°ƒç”¨åŠŸèƒ½ã€‚

## é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®ä½¿ç”¨shawhin/tool-use-finetuningæ•°æ®é›†å¯¹Googleçš„Gemma3-1bæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œé€šè¿‡LoRAï¼ˆLow-Rank Adaptationï¼‰æ–¹æ³•å®ç°å‚æ•°é«˜æ•ˆçš„å¾®è°ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿç†è§£å’Œæ‰§è¡Œå·¥å…·è°ƒç”¨ä»»åŠ¡ã€‚

### ğŸš€ æœ€æ–°ä¼˜åŒ–

- **ç®€åŒ–æ•°æ®å¤„ç†é€»è¾‘**ï¼šä¼˜åŒ–å·¥å…·è°ƒç”¨æ ¼å¼è½¬æ¢ï¼Œæé«˜å¤„ç†æ•ˆç‡
- **å¢å¼ºéªŒè¯æœºåˆ¶**ï¼šæ·»åŠ å·¥å…·è°ƒç”¨æ ¼å¼éªŒè¯å’Œé…ç½®éªŒè¯
- **é’ˆå¯¹æ€§è¯„ä¼°æŒ‡æ ‡**ï¼šæ–°å¢å·¥å…·è°ƒç”¨å‡†ç¡®ç‡ã€F1åˆ†æ•°ç­‰ä¸“ä¸šæŒ‡æ ‡
- **ä¼˜åŒ–é…ç½®ç®¡ç†**ï¼šç®€åŒ–é…ç½®æ–‡ä»¶ï¼Œå‡å°‘å†—ä½™å‚æ•°
- **å¢å¼ºæµ‹è¯•è¦†ç›–**ï¼šå®Œå–„å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•
- **æ€§èƒ½ä¼˜åŒ–**ï¼šæä¾›ä¼˜åŒ–ç‰ˆé…ç½®æ–‡ä»¶ï¼Œæå‡è®­ç»ƒæ•ˆç‡

## ç¯å¢ƒè¦æ±‚

- Python >= 3.9, < 3.14 (æ¨èPython 3.11.6æˆ–3.12.0)
- CUDAå…¼å®¹çš„GPUï¼ˆæ¨è16GB+æ˜¾å­˜ï¼‰
- UVåŒ…ç®¡ç†å™¨
- Hugging Faceè´¦å·ï¼ˆéœ€è¦ç”³è¯·Gemma3-1b-itæ¨¡å‹è®¿é—®æƒé™ï¼‰

> **æ³¨æ„**: å¦‚æœé‡åˆ°Pythonç‰ˆæœ¬é—®é¢˜ï¼Œè¯·å‚è€ƒ [WINDOWS_SETUP.md](WINDOWS_SETUP.md) è·å–è¯¦ç»†è§£å†³æ–¹æ¡ˆã€‚
> 
> **ä¸­å›½ç”¨æˆ·**: å¦‚æœé‡åˆ°ç½‘ç»œè¿æ¥é—®é¢˜ï¼Œè¯·ä½¿ç”¨ `scripts/train_china.bat` è„šæœ¬ï¼Œå®ƒä¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³é•œåƒç«™ã€‚

## å®‰è£…

1. å…‹éš†é¡¹ç›®ï¼š
```bash
git clone <your-repo-url>
cd gemma3-tool-finetuning
```

2. ä½¿ç”¨UVå®‰è£…ä¾èµ–ï¼š
```bash
uv sync
```

## é¡¹ç›®ç»“æ„

```
gemma3-tool-finetuning/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_processor.py      # æ•°æ®å¤„ç†æ¨¡å—ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
â”‚   â”œâ”€â”€ model_config.py        # æ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ trainer.py             # è®­ç»ƒå™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
â”‚   â”œâ”€â”€ utils.py               # å·¥å…·å‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
â”‚   â””â”€â”€ mirror_utils.py        # é•œåƒç«™å·¥å…·
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ training_config.yaml           # æ ‡å‡†è®­ç»ƒé…ç½®
â”‚   â”œâ”€â”€ training_config_optimized.yaml # ä¼˜åŒ–è®­ç»ƒé…ç½®
â”‚   â””â”€â”€ training_config_*.yaml         # å…¶ä»–ç¯å¢ƒé…ç½®
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ prepare_data.py        # æ•°æ®å‡†å¤‡è„šæœ¬
â”‚   â”œâ”€â”€ train.py               # è®­ç»ƒè„šæœ¬ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
â”‚   â”œâ”€â”€ evaluate.py            # è¯„ä¼°è„šæœ¬ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
â”‚   â””â”€â”€ train_*.bat            # ç¯å¢ƒç‰¹å®šè„šæœ¬
â”œâ”€â”€ tests/                     # æµ‹è¯•æ–‡ä»¶ï¼ˆå¢å¼ºç‰ˆï¼‰
â”œâ”€â”€ pyproject.toml            # é¡¹ç›®é…ç½®
â””â”€â”€ README.md                 # é¡¹ç›®æ–‡æ¡£
```

## ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿå¼€å§‹ï¼ˆæ¨èï¼‰

#### 1. ä½¿ç”¨ä¼˜åŒ–é…ç½®è®­ç»ƒ

```bash
# ä½¿ç”¨ä¼˜åŒ–é…ç½®è¿›è¡Œè®­ç»ƒ
uv run python scripts/train.py --config configs/training_config_optimized.yaml
```

#### 2. è¯„ä¼°æ¨¡å‹æ€§èƒ½

```bash
# è¯„ä¼°æ¨¡å‹å·¥å…·è°ƒç”¨èƒ½åŠ›
uv run python scripts/evaluate.py --model_path ./outputs --max_samples 100
```

### æ ‡å‡†è®­ç»ƒæµç¨‹

#### 1. æ•°æ®å‡†å¤‡

```bash
uv run python scripts/prepare_data.py
```

#### 2. å¼€å§‹è®­ç»ƒ

```bash
uv run python scripts/train.py --config configs/training_config.yaml
```

#### 3. è¯„ä¼°æ¨¡å‹

```bash
uv run python scripts/evaluate.py --model_path ./outputs/checkpoint-final
```

### ç¯å¢ƒç‰¹å®šè®­ç»ƒ

#### Windows CUDAç¯å¢ƒ

```cmd
scripts/setup_windows.bat
scripts/train_windows.bat
```

#### ä¸­å›½ç½‘ç»œç¯å¢ƒ

```cmd
scripts/train_china.bat
```

#### RTX 4090ç¯å¢ƒ

```cmd
scripts/train_rtx4090.bat
```

## é…ç½®è¯´æ˜

### ä¼˜åŒ–é…ç½®ç‰¹æ€§

**training_config_optimized.yaml** åŒ…å«ä»¥ä¸‹ä¼˜åŒ–ï¼š

- **æ•°æ®é›†é™åˆ¶**ï¼šé™åˆ¶ä¸º1000æ ·æœ¬ï¼Œæé«˜è®­ç»ƒæ•ˆç‡
- **åºåˆ—é•¿åº¦ä¼˜åŒ–**ï¼šå‡å°‘åˆ°1024ï¼Œé™ä½å†…å­˜å ç”¨
- **å­¦ä¹ ç‡è°ƒæ•´**ï¼šé™ä½åˆ°1e-4ï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§
- **è®­ç»ƒè½®æ•°ä¼˜åŒ–**ï¼šå‡å°‘åˆ°2è½®ï¼Œé¿å…è¿‡æ‹Ÿåˆ
- **è¯„ä¼°é—´éš”ä¼˜åŒ–**ï¼šå¢åŠ è¯„ä¼°é—´éš”ï¼Œå‡å°‘è®¡ç®—å¼€é”€
- **å†…å­˜ä¼˜åŒ–**ï¼šå¯ç”¨pin_memoryï¼Œæå‡æ•°æ®åŠ è½½æ•ˆç‡

### ä¸»è¦é…ç½®å‚æ•°

- `model.name`: åŸºç¡€æ¨¡å‹åç§°
- `dataset.max_samples`: æ•°æ®é›†å¤§å°é™åˆ¶
- `lora.r`: LoRA rankå‚æ•°
- `training.learning_rate`: å­¦ä¹ ç‡
- `training.num_train_epochs`: è®­ç»ƒè½®æ•°
- `data_processing.max_seq_length`: æœ€å¤§åºåˆ—é•¿åº¦

## è¯„ä¼°æŒ‡æ ‡

### æ–°å¢å·¥å…·è°ƒç”¨æŒ‡æ ‡

- **tool_call_accuracy**: å·¥å…·è°ƒç”¨å‡†ç¡®ç‡
- **tool_name_accuracy**: å·¥å…·åç§°å‡†ç¡®ç‡
- **tool_args_accuracy**: å·¥å…·å‚æ•°å‡†ç¡®ç‡
- **tool_call_f1**: å·¥å…·è°ƒç”¨F1åˆ†æ•°
- **exact_match**: å®Œå…¨åŒ¹é…ç‡

### æ ‡å‡†æŒ‡æ ‡

- **eval_loss**: éªŒè¯æŸå¤±
- **eval_accuracy**: éªŒè¯å‡†ç¡®ç‡

## æŠ€æœ¯æ ˆ

- **æ¨¡å‹**: Google Gemma3-1b
- **å¾®è°ƒæ–¹æ³•**: PEFT LoRA
- **æ•°æ®é›†**: shawhin/tool-use-finetuning
- **æ¡†æ¶**: Transformers, PyTorch
- **åŒ…ç®¡ç†**: UV

## æµ‹è¯•

è¿è¡Œæµ‹è¯•å¥—ä»¶ï¼š

```bash
uv run pytest tests/ -v
```

æµ‹è¯•è¦†ç›–ï¼š
- å·¥å…·è°ƒç”¨æ ¼å¼éªŒè¯
- æ•°æ®å¤„ç†é€»è¾‘
- é…ç½®éªŒè¯
- ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨ä¼˜åŒ–é…ç½®**ï¼šä¼˜å…ˆä½¿ç”¨ `training_config_optimized.yaml`
2. **è°ƒæ•´æ•°æ®é›†å¤§å°**ï¼šæ ¹æ®æ˜¾å­˜é™åˆ¶è°ƒæ•´ `max_samples`
3. **ä¼˜åŒ–åºåˆ—é•¿åº¦**ï¼šæ ¹æ®ä»»åŠ¡éœ€æ±‚è°ƒæ•´ `max_seq_length`
4. **ç›‘æ§èµ„æºä½¿ç”¨**ï¼šä½¿ç”¨ `log_system_info()` ç›‘æ§ç³»ç»ŸçŠ¶æ€

## è®¸å¯è¯

MIT License
