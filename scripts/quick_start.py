#!/usr/bin/env python3
"""
å¿«é€Ÿå¯åŠ¨è„šæœ¬
æä¾›å¤šç§å¾®è°ƒé€‰é¡¹çš„å¿«é€Ÿå¯åŠ¨
"""

import argparse
import logging
import sys
import os
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from src.utils import setup_logging


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Gemma3-1b å·¥å…·è°ƒç”¨å¾®è°ƒ - å¿«é€Ÿå¯åŠ¨")
    parser.add_argument(
        "--mode", 
        type=str, 
        default="local",
        choices=["local", "hf-jobs", "hf-spaces"],
        help="è¿è¡Œæ¨¡å¼"
    )
    parser.add_argument(
        "--flavor", 
        type=str, 
        default="a10g-small",
        choices=["t4-small", "t4-medium", "a10g-small", "a10g-large", "a100-large"],
        help="ç¡¬ä»¶é…ç½® (ä»…HF Jobsæ¨¡å¼)"
    )
    parser.add_argument(
        "--log_level", 
        type=str, 
        default="INFO",
        choices=["DEBUG", "INFO", "WARNING", "ERROR"],
        help="æ—¥å¿—çº§åˆ«"
    )
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    setup_logging(args.log_level)
    logger = logging.getLogger(__name__)
    
    logger.info("ğŸš€ Gemma3-1b å·¥å…·è°ƒç”¨å¾®è°ƒ - å¿«é€Ÿå¯åŠ¨")
    
    if args.mode == "local":
        logger.info("æœ¬åœ°è®­ç»ƒæ¨¡å¼")
        logger.info("è¯·ç¡®ä¿æ‚¨æœ‰è¶³å¤Ÿçš„GPUèµ„æº")
        logger.info("è¿è¡Œå‘½ä»¤: python scripts/train.py")
        
        # æ£€æŸ¥ç¯å¢ƒ
        try:
            import torch
            if torch.cuda.is_available():
                logger.info(f"âœ… æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name()}")
                logger.info(f"âœ… GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            else:
                logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°CUDAï¼Œè®­ç»ƒå°†åœ¨CPUä¸Šè¿›è¡Œï¼ˆä¸æ¨èï¼‰")
        except ImportError:
            logger.error("âŒ æœªå®‰è£…PyTorch")
            return
        
        # è¿è¡Œæœ¬åœ°è®­ç»ƒ
        os.system("python scripts/train.py")
        
    elif args.mode == "hf-jobs":
        logger.info("Hugging Face Jobsæ¨¡å¼")
        logger.info(f"ç¡¬ä»¶é…ç½®: {args.flavor}")
        
        # æ£€æŸ¥HF Token
        if not os.environ.get("HF_TOKEN"):
            logger.error("âŒ è¯·è®¾ç½®HF_TOKENç¯å¢ƒå˜é‡")
            logger.info("è¿è¡Œ: export HF_TOKEN='your_token'")
            return
        
        logger.info("âœ… HF Tokenå·²è®¾ç½®")
        
        # è¿è¡ŒHF Jobsè®­ç»ƒ
        cmd = f"python scripts/train_hf_jobs.py --flavor {args.flavor}"
        logger.info(f"è¿è¡Œå‘½ä»¤: {cmd}")
        os.system(cmd)
        
    elif args.mode == "hf-spaces":
        logger.info("Hugging Face Spacesæ¨¡å¼")
        logger.info("è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œ:")
        logger.info("1. å°†æ­¤é¡¹ç›®æ¨é€åˆ°Hugging Face Hub")
        logger.info("2. åˆ›å»ºæ–°çš„Spaceï¼Œé€‰æ‹©Gradioæ¨¡æ¿")
        logger.info("3. å‡çº§åˆ°GPUç¡¬ä»¶")
        logger.info("4. é€šè¿‡Webç•Œé¢å¯åŠ¨è®­ç»ƒ")
        
        # æ£€æŸ¥æ˜¯å¦åœ¨Spaceç¯å¢ƒä¸­
        if os.environ.get("SPACE_ID"):
            logger.info("âœ… æ£€æµ‹åˆ°Spaceç¯å¢ƒ")
            logger.info("å¯åŠ¨Spaceåº”ç”¨...")
            os.system("python app.py")
        else:
            logger.info("å½“å‰ä¸åœ¨Spaceç¯å¢ƒä¸­")
            logger.info("è¯·éƒ¨ç½²åˆ°Hugging Face Spacesåé‡è¯•")


if __name__ == "__main__":
    main()
